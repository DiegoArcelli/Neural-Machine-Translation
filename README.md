# Prompt-Tuning-Experiments
Code to train some NLP models on different downstream tasks using fine-tuning, prompt-tuning and prefix-tuning. 
The considered task are:
- Predict whether two questions have the same meaning using the Quora
Question Pairs2 dataset
- Computing the similarity between two sentences using the Semantic Tex-
tual Similarity Benchmark dataset
- Text summarization using the BillSum dataset
- Table to text using the E2E dataset
