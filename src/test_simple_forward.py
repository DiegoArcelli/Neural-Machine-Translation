import sys
sys.path.append("./models/")
from models.prompt_tuning_models import T5PromptTuningSimple
from utils import count_parameters
from transformers import AutoTokenizer
import torch

model = T5PromptTuningSimple.from_pretrained("t5-small", None, None, 10, 10, device="cuda")
model = model.to("cuda")

tokenizer = AutoTokenizer.from_pretrained("t5-small")

inputs = tokenizer(["Hello, my dog is cute", "I hate black cats"], padding=True, truncation=True, return_tensors="pt")
targets = tokenizer(["Ciao, il mio cane Ã¨ carino", "Odio i gatti neri"], padding=True, truncation=True, return_tensors="pt")

out = model(
    input_ids=inputs.input_ids,
    decoder_input_ids = targets.input_ids,
    attention_mask=inputs.attention_mask,
    decoder_attention_mask=targets.attention_mask,
    labels=targets.input_ids
)
print(out.keys())
logits = out.logits
print(out.loss)
print(logits.shape)